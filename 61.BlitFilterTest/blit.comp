#version 460 core

#ifndef _NBL_GLSL_WORKGROUP_SIZE_
#error "_NBL_GLSL_WORKGROUP_SIZE_ is not defined"
#endif

layout (local_size_x = _NBL_GLSL_WORKGROUP_SIZE_) in;

layout(push_constant) uniform Block
{
	uvec3 inDim;
	uvec3 outDim;

	vec3 negativeSupport;
	vec3 positiveSupport;

	uvec3 windowDim;
	uvec3 phaseCount;
} pc;

#define MAX_SMEM_SIZE (16*1024)

// need to change the type based on formats to not waste smem
shared vec4 scratchShared[MAX_SMEM_SIZE/8];

layout (set = 0, binding = 0) uniform sampler2D inImage;
// layout (set = 0, binding = 1, r32f) uniform writeonly image3D outImage;
layout (set = 0, binding = 1, rgba16f) uniform writeonly image2D outImage;

// Todo(achal): I don't think I need row_major here
layout (set = 0, binding = 2, std140, row_major) uniform Weights
{
	// Todo(achal): Think about what to put here as MAX_VALUE
	float data[1024*1024];
} weights;

layout (set = 0, binding = 3) buffer coherent AlphaHistogram
{
	uint data[];
} alphaHistogram;

void main()
{
	const vec3 scale = vec3(pc.inDim)/vec3(pc.outDim);

	// Todo(achal): Remove
	const uint channelCount = 4u;
	const uint sizeof_float = 4u;

	const uint windowPixelCount = pc.windowDim.x * pc.windowDim.y * pc.windowDim.z; // 21
	const uint smemPerWindow = windowPixelCount * channelCount * sizeof_float; // 336
	const uint windowsPerWG = MAX_SMEM_SIZE/smemPerWindow; // 48 // Todo(achal): Make this come in via push constants

	// Todo(achal): assert on the CPU windowPixelCount <= _NBL_GLSL_WORKGROUP_SIZE_
	const uint windowsPerStep = _NBL_GLSL_WORKGROUP_SIZE_/windowPixelCount; // 256/21 = 12
	const uint stepCount = (windowsPerWG + windowsPerStep - 1)/windowsPerStep; // 4

	const uint totalWindowCount = pc.outDim.x * pc.outDim.y * pc.outDim.z;

	for (uint step = 0u; step < stepCount; ++step)
	{
		// gl_LocalInvocationIndex = 252, 253, 254, 255 will give 12 + {0, 12, 24, 36}
		const uint stepLocalWindowIndex = gl_LocalInvocationIndex/windowPixelCount;
		if (stepLocalWindowIndex >= windowsPerStep)
			break;

		// 0:	0, 12, 24, 36
		// 1:	0, 12, 24, 36
		// ..
		// 20:	0, 12, 24, 36
		// ..
		// ..
		// 21:	1, 13, 25, 37
		// 22:	1, 13, 25, 37
		// ..
		// 41:	1, 13, 25, 37
		const uint wgLocalWindowIndex = stepLocalWindowIndex + step*windowsPerStep;

		// It could be the case that the last workgroup processes LESS THAN windowsPerWG windows
		const uint globalWindowIndex = gl_WorkGroupID.x * windowsPerWG + wgLocalWindowIndex;
		if (globalWindowIndex >= totalWindowCount)
			break;

		uvec3 globalWindowID;
		{
			const uint windowsPerSlice = pc.outDim.x * pc.outDim.y;

			globalWindowID.z = globalWindowIndex/windowsPerSlice;

			const uint sliceLocalIndex = globalWindowIndex % windowsPerSlice;

			globalWindowID.y = sliceLocalIndex/pc.outDim.x;
			globalWindowID.x = sliceLocalIndex % pc.outDim.x;
		}

		const vec3 outputPixelCenter = (globalWindowID + vec3(0.5f))*scale;

		const ivec3 windowMinCoord = ivec3(ceil( outputPixelCenter-vec3(0.5f) - abs(pc.negativeSupport) )); // this can be negative

		const uint windowLocalPixelIndex = gl_LocalInvocationIndex % windowPixelCount;
		uvec3 windowLocalPixelID;
		{
			const uint pixelsPerSlice = pc.windowDim.x * pc.windowDim.y;

			windowLocalPixelID.z = windowLocalPixelIndex/pixelsPerSlice;

			const uint sliceLocalIndex = windowLocalPixelIndex % pixelsPerSlice;

			windowLocalPixelID.x = sliceLocalIndex/pc.windowDim.x;
			windowLocalPixelID.y = sliceLocalIndex % pc.windowDim.x;
		}

		const ivec3 inputPixelCoord = windowMinCoord + ivec3(windowLocalPixelID);
		const vec3 inputPixelCenter = vec3(inputPixelCoord) + vec3(0.5f);

		const uvec3 windowPhase = globalWindowID % pc.phaseCount;
		uvec3 lutIndex;
		lutIndex.x = windowPhase.x*pc.windowDim.x + windowLocalPixelID.x;
		lutIndex.y = pc.phaseCount.x*pc.windowDim.x + windowPhase.y*pc.windowDim.y + windowLocalPixelID.y;
		lutIndex.z = pc.phaseCount.x*pc.windowDim.x + pc.phaseCount.y*pc.windowDim.y + windowLocalPixelID.z;

		// Premultiplying weights together like this can butcher floating point precision, is it a better idea to first multiply on the CPU with double precision and then upload??
		const vec3 weight = vec3(weights.data[lutIndex.x], weights.data[lutIndex.y], weights.data[lutIndex.z]);
		scratchShared[wgLocalWindowIndex*windowPixelCount + windowLocalPixelIndex] = texelFetch(inImage, inputPixelCoord.xy/*z*/, 0)*weight.x*weight.y/*weight.z*/;
	}
	barrier();

	const uvec3 stride = uvec3(1u, pc.windowDim.x, pc.windowDim.x*pc.windowDim.y);
	const uint axisCount = 2u; // Todo(achal): Get it via push constants
	for (uint axis = 0u; axis < axisCount; ++axis)
	{
		const uint stride = stride[axis]; // { 1, 3, 21 }
		const uint elementCount = (windowPixelCount * windowsPerWG)/stride; // { 21*48/1 = 1008, 21*48/3 = 336, 21*48/21 = 48 }

		const uint adderLength = pc.windowDim[axis]; // { 3, 7, 1 }
		const uint adderCount = elementCount/adderLength; // { 1008/3 = 336, 336/7 = 48, 48/1 = 48 }
		const uint addersPerStep = _NBL_GLSL_WORKGROUP_SIZE_/adderLength; // { 256/3 = 85, 256/7 = 36, 256/1 = 256 }
		const uint adderStepCount = (adderCount+addersPerStep-1)/addersPerStep; // { (336+85-1)/85 = 4, (48+36-1)/36 = 2, (48+256-1)/256 = 1 }

		for (uint adderStep = 0u; adderStep < adderStepCount; ++adderStep)
		{
			const uint wgLocalAdderIndex = adderStep*addersPerStep + gl_LocalInvocationIndex/adderLength;
			const uint adderLocalPixelIndex = gl_LocalInvocationIndex % adderLength;

			// To make this code dynamically uniform we have to ensure that the following for loop runs at least once
			// even if adderLength = 1, hence the `max`
			const uint reduceStepCount = max(uint(ceil(log2(float(adderLength)))), 1u); // { 2, 3, 1 }
			for (uint reduceStep = 0u; reduceStep < reduceStepCount; ++reduceStep)
			{
				const uint offset = (1u << reduceStep); // { {1,2}, {1,2,4}, {1} }
				const uint baseIndex = (1u << (reduceStep + 1u))*adderLocalPixelIndex;

				if ((baseIndex < adderLength) && (wgLocalAdderIndex < adderCount))
				{
					vec4 addend = vec4(0.f);
					if (baseIndex + offset < adderLength) // Don't need any kind of finer bounds checking here since we're ensuring that all windows fit COMPLETELY in a workgroup
						addend = scratchShared[((baseIndex + wgLocalAdderIndex*adderLength) + offset)*stride];

					scratchShared[(baseIndex + wgLocalAdderIndex*adderLength)*stride] += addend;
				}
				barrier();
			}
		}
	}

	for (uint step = 0u; step < stepCount; ++step)
	{
		const bool firstInvocationOfWindow = (gl_LocalInvocationIndex % windowPixelCount) == 0u ? true : false;
		if (!firstInvocationOfWindow)
			break;

		const uint stepLocalWindowIndex = gl_LocalInvocationIndex/windowPixelCount;
		if (stepLocalWindowIndex >= windowsPerStep) // This is important, otherwise some invocations in this step might interfere with next step's windows.
			break;

		// This doesn't need additional bounds checking because windows are packed tightly in workgroups. Same cannot be said for above where there might be some
		// empty space at the end of a step-- where a full window could not fit.
		const uint wgLocalWindowIndex = stepLocalWindowIndex + step*windowsPerStep;
		const uint globalWindowIndex = gl_WorkGroupID.x * windowsPerWG + wgLocalWindowIndex;
		if (globalWindowIndex >= totalWindowCount)
			break;

		const vec4 result = scratchShared[wgLocalWindowIndex*windowPixelCount];

		const uint bucketIndex = packUnorm4x8(vec4(result.a, 0.f, 0.f, 0.f));
		atomicAdd(alphaHistogram.data[bucketIndex], 1u);

		uvec3 globalWindowID;
		{
			const uint windowsPerSlice = pc.outDim.x * pc.outDim.y;

			globalWindowID.z = globalWindowIndex/windowsPerSlice;

			const uint sliceLocalIndex = globalWindowIndex % windowsPerSlice;

			globalWindowID.y = sliceLocalIndex/pc.outDim.x;
			globalWindowID.x = sliceLocalIndex % pc.outDim.x;
		}

		imageStore(outImage, ivec2(globalWindowID.xy), result);
	}
}