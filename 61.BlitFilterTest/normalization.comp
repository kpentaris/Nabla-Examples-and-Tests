#version 460 core

layout (local_size_x = _NBL_GLSL_WORKGROUP_SIZE_X_, local_size_y = _NBL_GLSL_WORKGROUP_SIZE_Y_, local_size_z = 1) in;

#define _NBL_GLSL_WORKGROUP_SIZE_ (_NBL_GLSL_WORKGROUP_SIZE_X_ * _NBL_GLSL_WORKGROUP_SIZE_Y_)

#include <nbl/builtin/glsl/workgroup/arithmetic.glsl>

layout (push_constant) uniform Block
{
	uvec3 outImageDim;
	uint padding;
	uint inPixelCount;
	float oldReferenceAlpha;
} pc;

layout (set = 0, binding = 0, rgba16f) uniform image2D inImage;

layout (set = 0, binding = 1) buffer restrict readonly AlphaHistogram
{
	uint data[_NBL_GLSL_BIN_COUNT_];
} alphaHistogram;

layout (set = 0, binding = 2) buffer restrict readonly PassedInputPixelCount
{
	uint data;
} passedInputPixelCount;

#define scratchShared _NBL_GLSL_SCRATCH_SHARED_DEFINED_

void main()
{
	const uint histogramVal = alphaHistogram.data[gl_LocalInvocationIndex];
	const uint cumHistogramVal = nbl_glsl_workgroupInclusiveAdd(histogramVal);

	scratchShared[gl_LocalInvocationIndex] = cumHistogramVal;
	barrier();

	const uint outputPixelCount = pc.outImageDim.x * pc.outImageDim.y * pc.outImageDim.z;

	// Considering the max dim is 16384
	//		max(outputPixelCount) is 2^42
	//		max(passedInputPixelCount.data) is 2^42
	// i.e the max value of their multiplication can be 2^84
	// for which even umulExtended is not enough, then I must take a CPU path.
	// In fact, if I detect the passedInputPixelCount*outputPixelCount > 2^56 then I
	// must take the CPU path or just fail blit entirely
	uint outMsb, outLsb;
	umulExtended(passedInputPixelCount.data, outputPixelCount, outMsb, outLsb);

	const uint MAX_UINT = ~0u;
	const float msbRatio = float(outMsb)/float(pc.inPixelCount);
	const uint quotient = uint((msbRatio * MAX_UINT) + msbRatio) + outLsb/pc.inPixelCount;

	const uint pixelsShouldPassCount = quotient;
	const uint pixelsShouldFailCount = outputPixelCount - pixelsShouldPassCount;

	uint bucketIndex;
	{
		uint begin = 0u;
		const uint end = _NBL_GLSL_BIN_COUNT_;
		const uint value = pixelsShouldFailCount;
		uint len = end - begin;
		if (NBL_GLSL_IS_NOT_POT(len))
		{
		    const uint newLen = 0x1u << findMSB(len);
		    const uint diff = len - newLen;

		    begin = NBL_GLSL_LESS(value, NBL_GLSL_EVAL(scratchShared)[newLen]) ? 0u : diff;
		    len = newLen;
		}

		while (len != 0u)
		{
		    begin += NBL_GLSL_LESS(value, NBL_GLSL_EVAL(scratchShared)[begin + (len >>= 1u)]) ? 0u : len;
		    begin += NBL_GLSL_LESS(value, NBL_GLSL_EVAL(scratchShared)[begin + (len >>= 1u)]) ? 0u : len;
		}

		bucketIndex = begin + (NBL_GLSL_LESS(value, NBL_GLSL_EVAL(scratchShared)[begin]) ? 0u : 1u);
	}

	// Essentially inverting packUnorm4x8. Would unpackUnorm4x8 work here?
	const float newReferenceAlpha = min( (bucketIndex-0.5f)/float(_NBL_GLSL_BIN_COUNT_ - 1), 1.f);

	const float alphaScale = pc.oldReferenceAlpha/newReferenceAlpha;

	if (all(lessThan(gl_GlobalInvocationID.xy, pc.outImageDim.xy)))
	{
		const vec4 pixel = imageLoad(inImage, ivec2(gl_GlobalInvocationID.xy));
		imageStore( inImage, ivec2(gl_GlobalInvocationID.xy), vec4(pixel.rgb, pixel.a * alphaScale) );
	}
}